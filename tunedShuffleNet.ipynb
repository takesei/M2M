{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save/load func\n",
    "def save_checkpoint(path, epoch, model):\n",
    "    save_path = os.path.join(path, f\"shufflenet_epoch_{epoch}.pkl\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Checkpoint saved to {save_path}\")\n",
    "\n",
    "def load_checkpoint(model_dir, epoch, model):\n",
    "    load_path = os.path.join(model_dir, f\"shufflenet_epoch_{epoch}.pkl\")\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(f\"Checkpoint loaded from {load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA detected\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "# random seeds\n",
    "np.random.seed(723)\n",
    "random.seed(723)\n",
    "torch.manual_seed(723)\n",
    "torch.cuda.manual_seed(723)\n",
    "\n",
    "# Networks\n",
    "batchsize = 32\n",
    "epochs = 10\n",
    "epoch_start = 1\n",
    "\n",
    "# GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"CUDA detected\")\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    \n",
    "# PATH\n",
    "checkout_dir = \"./checkout\"\n",
    "if os.path.exists(checkout_dir) is False:\n",
    "    os.mkdir(checkout_dir)\n",
    "    print(\"create ./checkout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/deepstation/.cache/torch/hub/pytorch_vision_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mount model in CUDA\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "n_classes = 3\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "# model = models.shufflenet_v2_x0_5(pretrained=True).to(device)\n",
    "model = torch.hub.load(\"pytorch/vision\", \"shufflenet_v2_x1_0\", pretrained=True)\n",
    "n_filters = model.fc.in_features\n",
    "model.fc = nn.Linear(n_filters, n_classes)\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    print(\"mount model in CUDA\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=5e-4)\n",
    "use_scheduler= False\n",
    "if use_scheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dataset: 1351\n",
      "Number of Train Dataset: 1080\n",
      "Number of Test Dataset: 271\n",
      "epoch: 10\n",
      "batchsize: 32\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]), transforms.RandomHorizontalFlip()\n",
    "    , transforms.ToTensor()\n",
    "    , transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=\"trashes\", transform=data_transform)\n",
    "\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "print(f\"Number of Dataset: {dataset_size}\")\n",
    "print(f\"Number of Train Dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of Test Dataset: {len(test_dataset)}\")\n",
    "print(f\"epoch: {epochs}\")\n",
    "print(f\"batchsize: {batchsize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, train_loader, epoch):\n",
    "    model.train()\n",
    "    print(f\"\\nEpoch: {epoch}\")\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "    print(f\"Train Loss:{train_loss/(batch_idx+1)} | Acc:{100.*correct/total} ({correct}/{total})\")\n",
    "    return train_loss, 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(model, test_loader, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "    print(f\"Test Loss:{test_loss/batch_idx+1} | Acc:{100.*correct/total} ({correct}/{total})\")\n",
    "    return test_loss, 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluation(model_dir, epoch, model, test_loader):\n",
    "    print(\"\\nEvaluation\")\n",
    "    load_checkpoint(model_dir, epoch, model)\n",
    "    model.eval()\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outpus = model(image)\n",
    "        _, predictions = outpus.max(1)\n",
    "        y_test.append(label.data.cpu().numpy())\n",
    "        y_pred.append(predictions.data.cpu().numpy())\n",
    "    y_test = np.concatenate(y_test)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, confusion matrix: \\n{confusion_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to restart learning, set model_load as True\n",
    "model_load = False\n",
    "epoch_start = 0\n",
    "\n",
    "if model_load:\n",
    "    load_checkpoint(checkout_dir, epoch_start, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 24, 122, 122]             648\n",
      "       BatchNorm2d-2         [-1, 24, 122, 122]              48\n",
      "              ReLU-3         [-1, 24, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 24, 61, 61]               0\n",
      "            Conv2d-5           [-1, 24, 31, 31]             216\n",
      "       BatchNorm2d-6           [-1, 24, 31, 31]              48\n",
      "            Conv2d-7           [-1, 58, 31, 31]           1,392\n",
      "       BatchNorm2d-8           [-1, 58, 31, 31]             116\n",
      "              ReLU-9           [-1, 58, 31, 31]               0\n",
      "           Conv2d-10           [-1, 58, 61, 61]           1,392\n",
      "      BatchNorm2d-11           [-1, 58, 61, 61]             116\n",
      "             ReLU-12           [-1, 58, 61, 61]               0\n",
      "           Conv2d-13           [-1, 58, 31, 31]             522\n",
      "      BatchNorm2d-14           [-1, 58, 31, 31]             116\n",
      "           Conv2d-15           [-1, 58, 31, 31]           3,364\n",
      "      BatchNorm2d-16           [-1, 58, 31, 31]             116\n",
      "             ReLU-17           [-1, 58, 31, 31]               0\n",
      " InvertedResidual-18          [-1, 116, 31, 31]               0\n",
      "           Conv2d-19           [-1, 58, 31, 31]           3,364\n",
      "      BatchNorm2d-20           [-1, 58, 31, 31]             116\n",
      "             ReLU-21           [-1, 58, 31, 31]               0\n",
      "           Conv2d-22           [-1, 58, 31, 31]             522\n",
      "      BatchNorm2d-23           [-1, 58, 31, 31]             116\n",
      "           Conv2d-24           [-1, 58, 31, 31]           3,364\n",
      "      BatchNorm2d-25           [-1, 58, 31, 31]             116\n",
      "             ReLU-26           [-1, 58, 31, 31]               0\n",
      " InvertedResidual-27          [-1, 116, 31, 31]               0\n",
      "           Conv2d-28           [-1, 58, 31, 31]           3,364\n",
      "      BatchNorm2d-29           [-1, 58, 31, 31]             116\n",
      "             ReLU-30           [-1, 58, 31, 31]               0\n",
      "           Conv2d-31           [-1, 58, 31, 31]             522\n",
      "      BatchNorm2d-32           [-1, 58, 31, 31]             116\n",
      "           Conv2d-33           [-1, 58, 31, 31]           3,364\n",
      "      BatchNorm2d-34           [-1, 58, 31, 31]             116\n",
      "             ReLU-35           [-1, 58, 31, 31]               0\n",
      " InvertedResidual-36          [-1, 116, 31, 31]               0\n",
      "           Conv2d-37           [-1, 58, 31, 31]           3,364\n",
      "      BatchNorm2d-38           [-1, 58, 31, 31]             116\n",
      "             ReLU-39           [-1, 58, 31, 31]               0\n",
      "           Conv2d-40           [-1, 58, 31, 31]             522\n",
      "      BatchNorm2d-41           [-1, 58, 31, 31]             116\n",
      "           Conv2d-42           [-1, 58, 31, 31]           3,364\n",
      "      BatchNorm2d-43           [-1, 58, 31, 31]             116\n",
      "             ReLU-44           [-1, 58, 31, 31]               0\n",
      " InvertedResidual-45          [-1, 116, 31, 31]               0\n",
      "           Conv2d-46          [-1, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-47          [-1, 116, 16, 16]             232\n",
      "           Conv2d-48          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-49          [-1, 116, 16, 16]             232\n",
      "             ReLU-50          [-1, 116, 16, 16]               0\n",
      "           Conv2d-51          [-1, 116, 31, 31]          13,456\n",
      "      BatchNorm2d-52          [-1, 116, 31, 31]             232\n",
      "             ReLU-53          [-1, 116, 31, 31]               0\n",
      "           Conv2d-54          [-1, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-55          [-1, 116, 16, 16]             232\n",
      "           Conv2d-56          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-57          [-1, 116, 16, 16]             232\n",
      "             ReLU-58          [-1, 116, 16, 16]               0\n",
      " InvertedResidual-59          [-1, 232, 16, 16]               0\n",
      "           Conv2d-60          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-61          [-1, 116, 16, 16]             232\n",
      "             ReLU-62          [-1, 116, 16, 16]               0\n",
      "           Conv2d-63          [-1, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-64          [-1, 116, 16, 16]             232\n",
      "           Conv2d-65          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-66          [-1, 116, 16, 16]             232\n",
      "             ReLU-67          [-1, 116, 16, 16]               0\n",
      " InvertedResidual-68          [-1, 232, 16, 16]               0\n",
      "           Conv2d-69          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-70          [-1, 116, 16, 16]             232\n",
      "             ReLU-71          [-1, 116, 16, 16]               0\n",
      "           Conv2d-72          [-1, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-73          [-1, 116, 16, 16]             232\n",
      "           Conv2d-74          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-75          [-1, 116, 16, 16]             232\n",
      "             ReLU-76          [-1, 116, 16, 16]               0\n",
      " InvertedResidual-77          [-1, 232, 16, 16]               0\n",
      "           Conv2d-78          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-79          [-1, 116, 16, 16]             232\n",
      "             ReLU-80          [-1, 116, 16, 16]               0\n",
      "           Conv2d-81          [-1, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-82          [-1, 116, 16, 16]             232\n",
      "           Conv2d-83          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-84          [-1, 116, 16, 16]             232\n",
      "             ReLU-85          [-1, 116, 16, 16]               0\n",
      " InvertedResidual-86          [-1, 232, 16, 16]               0\n",
      "           Conv2d-87          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-88          [-1, 116, 16, 16]             232\n",
      "             ReLU-89          [-1, 116, 16, 16]               0\n",
      "           Conv2d-90          [-1, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-91          [-1, 116, 16, 16]             232\n",
      "           Conv2d-92          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-93          [-1, 116, 16, 16]             232\n",
      "             ReLU-94          [-1, 116, 16, 16]               0\n",
      " InvertedResidual-95          [-1, 232, 16, 16]               0\n",
      "           Conv2d-96          [-1, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-97          [-1, 116, 16, 16]             232\n",
      "             ReLU-98          [-1, 116, 16, 16]               0\n",
      "           Conv2d-99          [-1, 116, 16, 16]           1,044\n",
      "     BatchNorm2d-100          [-1, 116, 16, 16]             232\n",
      "          Conv2d-101          [-1, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-102          [-1, 116, 16, 16]             232\n",
      "            ReLU-103          [-1, 116, 16, 16]               0\n",
      "InvertedResidual-104          [-1, 232, 16, 16]               0\n",
      "          Conv2d-105          [-1, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-106          [-1, 116, 16, 16]             232\n",
      "            ReLU-107          [-1, 116, 16, 16]               0\n",
      "          Conv2d-108          [-1, 116, 16, 16]           1,044\n",
      "     BatchNorm2d-109          [-1, 116, 16, 16]             232\n",
      "          Conv2d-110          [-1, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-111          [-1, 116, 16, 16]             232\n",
      "            ReLU-112          [-1, 116, 16, 16]               0\n",
      "InvertedResidual-113          [-1, 232, 16, 16]               0\n",
      "          Conv2d-114          [-1, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-115          [-1, 116, 16, 16]             232\n",
      "            ReLU-116          [-1, 116, 16, 16]               0\n",
      "          Conv2d-117          [-1, 116, 16, 16]           1,044\n",
      "     BatchNorm2d-118          [-1, 116, 16, 16]             232\n",
      "          Conv2d-119          [-1, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-120          [-1, 116, 16, 16]             232\n",
      "            ReLU-121          [-1, 116, 16, 16]               0\n",
      "InvertedResidual-122          [-1, 232, 16, 16]               0\n",
      "          Conv2d-123            [-1, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-124            [-1, 232, 8, 8]             464\n",
      "          Conv2d-125            [-1, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-126            [-1, 232, 8, 8]             464\n",
      "            ReLU-127            [-1, 232, 8, 8]               0\n",
      "          Conv2d-128          [-1, 232, 16, 16]          53,824\n",
      "     BatchNorm2d-129          [-1, 232, 16, 16]             464\n",
      "            ReLU-130          [-1, 232, 16, 16]               0\n",
      "          Conv2d-131            [-1, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-132            [-1, 232, 8, 8]             464\n",
      "          Conv2d-133            [-1, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-134            [-1, 232, 8, 8]             464\n",
      "            ReLU-135            [-1, 232, 8, 8]               0\n",
      "InvertedResidual-136            [-1, 464, 8, 8]               0\n",
      "          Conv2d-137            [-1, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-138            [-1, 232, 8, 8]             464\n",
      "            ReLU-139            [-1, 232, 8, 8]               0\n",
      "          Conv2d-140            [-1, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-141            [-1, 232, 8, 8]             464\n",
      "          Conv2d-142            [-1, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-143            [-1, 232, 8, 8]             464\n",
      "            ReLU-144            [-1, 232, 8, 8]               0\n",
      "InvertedResidual-145            [-1, 464, 8, 8]               0\n",
      "          Conv2d-146            [-1, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-147            [-1, 232, 8, 8]             464\n",
      "            ReLU-148            [-1, 232, 8, 8]               0\n",
      "          Conv2d-149            [-1, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-150            [-1, 232, 8, 8]             464\n",
      "          Conv2d-151            [-1, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-152            [-1, 232, 8, 8]             464\n",
      "            ReLU-153            [-1, 232, 8, 8]               0\n",
      "InvertedResidual-154            [-1, 464, 8, 8]               0\n",
      "          Conv2d-155            [-1, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-156            [-1, 232, 8, 8]             464\n",
      "            ReLU-157            [-1, 232, 8, 8]               0\n",
      "          Conv2d-158            [-1, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-159            [-1, 232, 8, 8]             464\n",
      "          Conv2d-160            [-1, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-161            [-1, 232, 8, 8]             464\n",
      "            ReLU-162            [-1, 232, 8, 8]               0\n",
      "InvertedResidual-163            [-1, 464, 8, 8]               0\n",
      "          Conv2d-164           [-1, 1024, 8, 8]         475,136\n",
      "     BatchNorm2d-165           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-166           [-1, 1024, 8, 8]               0\n",
      "          Linear-167                    [-1, 3]           3,075\n",
      "================================================================\n",
      "Total params: 1,256,679\n",
      "Trainable params: 1,256,679\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 59.91\n",
      "Params size (MB): 4.79\n",
      "Estimated Total Size (MB): 65.38\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepstation/anaconda3/envs/jetson/lib/python3.7/site-packages/PIL/Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/home/deepstation/anaconda3/envs/jetson/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:804: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:1.0968723367242252 | Acc:36.574074074074076 (395/1080)\n",
      "Test Loss:2.2263263016939163 | Acc:39.11439114391144 (106/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_0.pkl\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss:1.0854008267907536 | Acc:44.907407407407405 (485/1080)\n",
      "Test Loss:2.2122392654418945 | Acc:47.601476014760145 (129/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_1.pkl\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss:1.0707262754440308 | Acc:38.05555555555556 (411/1080)\n",
      "Test Loss:2.1903647631406784 | Acc:48.708487084870846 (132/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_2.pkl\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss:1.047570856178508 | Acc:59.53703703703704 (643/1080)\n",
      "Test Loss:2.1611551344394684 | Acc:59.77859778597786 (162/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_3.pkl\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss:1.0072052619036507 | Acc:67.68518518518519 (731/1080)\n",
      "Test Loss:2.1048603877425194 | Acc:68.26568265682657 (185/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_4.pkl\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss:0.9380653868703281 | Acc:75.27777777777777 (813/1080)\n",
      "Test Loss:2.0018962398171425 | Acc:74.53874538745387 (202/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_5.pkl\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss:0.819017990547068 | Acc:77.5 (837/1080)\n",
      "Test Loss:1.8872587755322456 | Acc:76.75276752767527 (208/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_6.pkl\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss:0.6669651497812832 | Acc:82.77777777777777 (894/1080)\n",
      "Test Loss:1.715468980371952 | Acc:81.91881918819188 (222/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_7.pkl\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss:0.499018314130166 | Acc:90.37037037037037 (976/1080)\n",
      "Test Loss:1.544319424778223 | Acc:88.19188191881919 (239/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_8.pkl\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss:0.3494029115228092 | Acc:94.35185185185185 (1019/1080)\n",
      "Test Loss:1.4446706362068653 | Acc:90.03690036900369 (244/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_9.pkl\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss:0.23671700893079534 | Acc:96.20370370370371 (1039/1080)\n",
      "Test Loss:1.2896579205989838 | Acc:94.09594095940959 (255/271)\n",
      "Checkpoint saved to ./checkout/shufflenet_epoch_10.pkl\n",
      "\n",
      "Evaluation\n",
      "Checkpoint loaded from ./checkout/shufflenet_epoch_10.pkl\n",
      "Accuracy: 0.9446494464944649, confusion matrix: \n",
      "[[89  1  6]\n",
      " [ 2 99  3]\n",
      " [ 1  2 68]]\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    summary(model, (3, 244, 244))\n",
    "\n",
    "    train_loss_log = []\n",
    "    test_loss_log = []\n",
    "    train_acc_log = []\n",
    "    test_acc_log = []\n",
    "\n",
    "    for epoch in range(epoch_start, epochs + 1):\n",
    "        train_loss, train_acc = train(model, train_loader, epoch)\n",
    "        test_loss, test_acc = test(model, test_loader, epoch)\n",
    "        train_loss_log.append(train_loss)\n",
    "        test_loss_log.append(test_loss)\n",
    "        train_acc_log.append(train_acc)\n",
    "        test_acc_log.append(test_acc)\n",
    "        save_checkpoint(checkout_dir, epoch, model)\n",
    "    evaluation(checkout_dir, epochs, model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
