{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save/load func\n",
    "def save_checkpoint(path, epoch, model):\n",
    "    save_path = os.path.join(path, f\"mobilenet_epoch_{epoch}.pkl\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Checkpoint saved to {save_path}\")\n",
    "\n",
    "def load_checkpoint(model_dir, epoch, model):\n",
    "    load_path = os.path.join(model_dir, f\"mobilenet_epoch_{epoch}.pkl\")\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(f\"Checkpoint loaded from {load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA detected\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "# random seeds\n",
    "np.random.seed(723)\n",
    "random.seed(723)\n",
    "torch.manual_seed(723)\n",
    "torch.cuda.manual_seed(723)\n",
    "\n",
    "# Networks\n",
    "batchsize = 32\n",
    "epochs = 10\n",
    "epoch_start = 1\n",
    "\n",
    "# GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"CUDA detected\")\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    \n",
    "# PATH\n",
    "checkout_dir = \"./checkout\"\n",
    "if os.path.exists(checkout_dir) is False:\n",
    "    os.mkdir(checkout_dir)\n",
    "    print(\"create ./checkout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mount model in CUDA\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "n_classes = 3\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "model = models.mobilenet_v2(pretrained=True).to(device)\n",
    "n_filters = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(n_filters, n_classes)\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    print(\"mount model in CUDA\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=5e-4)\n",
    "use_scheduler= False\n",
    "if use_scheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dataset: 1351\n",
      "Number of Train Dataset: 1080\n",
      "Number of Test Dataset: 271\n",
      "epoch: 10\n",
      "batchsize: 32\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]), transforms.RandomHorizontalFlip()\n",
    "    , transforms.ToTensor()\n",
    "    , transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=\"trashes\", transform=data_transform)\n",
    "\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "print(f\"Number of Dataset: {dataset_size}\")\n",
    "print(f\"Number of Train Dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of Test Dataset: {len(test_dataset)}\")\n",
    "print(f\"epoch: {epochs}\")\n",
    "print(f\"batchsize: {batchsize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, train_loader, epoch):\n",
    "    model.train()\n",
    "    print(f\"\\nEpoch: {epoch}\")\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "    print(f\"Train Loss:{train_loss/(batch_idx+1)} | Acc:{100.*correct/total} ({correct}/{total})\")\n",
    "    return train_loss, 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(model, test_loader, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "    print(f\"Test Loss:{test_loss/batch_idx+1} | Acc:{100.*correct/total} ({correct}/{total})\")\n",
    "    return test_loss, 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluation(model_dir, epoch, model, test_loader):\n",
    "    print(\"\\nEvaluation\")\n",
    "    load_checkpoint(model_dir, epoch, model)\n",
    "    model.eval()\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outpus = model(image)\n",
    "        _, predictions = outpus.max(1)\n",
    "        y_test.append(label.data.cpu().numpy())\n",
    "        y_pred.append(predictions.data.cpu().numpy())\n",
    "    y_test = np.concatenate(y_test)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, confusion matrix: \\n{confusion_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to restart learning, set model_load as True\n",
    "model_load = False\n",
    "epoch_start = 0\n",
    "\n",
    "if model_load:\n",
    "    load_checkpoint(checkout_dir, epoch_start, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 122, 122]             864\n",
      "       BatchNorm2d-2         [-1, 32, 122, 122]              64\n",
      "             ReLU6-3         [-1, 32, 122, 122]               0\n",
      "            Conv2d-4         [-1, 32, 122, 122]             288\n",
      "       BatchNorm2d-5         [-1, 32, 122, 122]              64\n",
      "             ReLU6-6         [-1, 32, 122, 122]               0\n",
      "            Conv2d-7         [-1, 16, 122, 122]             512\n",
      "       BatchNorm2d-8         [-1, 16, 122, 122]              32\n",
      "  InvertedResidual-9         [-1, 16, 122, 122]               0\n",
      "           Conv2d-10         [-1, 96, 122, 122]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 122, 122]             192\n",
      "            ReLU6-12         [-1, 96, 122, 122]               0\n",
      "           Conv2d-13           [-1, 96, 61, 61]             864\n",
      "      BatchNorm2d-14           [-1, 96, 61, 61]             192\n",
      "            ReLU6-15           [-1, 96, 61, 61]               0\n",
      "           Conv2d-16           [-1, 24, 61, 61]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-18           [-1, 24, 61, 61]               0\n",
      "           Conv2d-19          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 61, 61]             288\n",
      "            ReLU6-21          [-1, 144, 61, 61]               0\n",
      "           Conv2d-22          [-1, 144, 61, 61]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 61, 61]             288\n",
      "            ReLU6-24          [-1, 144, 61, 61]               0\n",
      "           Conv2d-25           [-1, 24, 61, 61]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-27           [-1, 24, 61, 61]               0\n",
      "           Conv2d-28          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 61, 61]             288\n",
      "            ReLU6-30          [-1, 144, 61, 61]               0\n",
      "           Conv2d-31          [-1, 144, 31, 31]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 31, 31]             288\n",
      "            ReLU6-33          [-1, 144, 31, 31]               0\n",
      "           Conv2d-34           [-1, 32, 31, 31]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-36           [-1, 32, 31, 31]               0\n",
      "           Conv2d-37          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 31, 31]             384\n",
      "            ReLU6-39          [-1, 192, 31, 31]               0\n",
      "           Conv2d-40          [-1, 192, 31, 31]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 31, 31]             384\n",
      "            ReLU6-42          [-1, 192, 31, 31]               0\n",
      "           Conv2d-43           [-1, 32, 31, 31]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-45           [-1, 32, 31, 31]               0\n",
      "           Conv2d-46          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 31, 31]             384\n",
      "            ReLU6-48          [-1, 192, 31, 31]               0\n",
      "           Conv2d-49          [-1, 192, 31, 31]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 31, 31]             384\n",
      "            ReLU6-51          [-1, 192, 31, 31]               0\n",
      "           Conv2d-52           [-1, 32, 31, 31]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-54           [-1, 32, 31, 31]               0\n",
      "           Conv2d-55          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 31, 31]             384\n",
      "            ReLU6-57          [-1, 192, 31, 31]               0\n",
      "           Conv2d-58          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 16, 16]             384\n",
      "            ReLU6-60          [-1, 192, 16, 16]               0\n",
      "           Conv2d-61           [-1, 64, 16, 16]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-63           [-1, 64, 16, 16]               0\n",
      "           Conv2d-64          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 16, 16]             768\n",
      "            ReLU6-66          [-1, 384, 16, 16]               0\n",
      "           Conv2d-67          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 16, 16]             768\n",
      "            ReLU6-69          [-1, 384, 16, 16]               0\n",
      "           Conv2d-70           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-72           [-1, 64, 16, 16]               0\n",
      "           Conv2d-73          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 16, 16]             768\n",
      "            ReLU6-75          [-1, 384, 16, 16]               0\n",
      "           Conv2d-76          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 16, 16]             768\n",
      "            ReLU6-78          [-1, 384, 16, 16]               0\n",
      "           Conv2d-79           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-81           [-1, 64, 16, 16]               0\n",
      "           Conv2d-82          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 16, 16]             768\n",
      "            ReLU6-84          [-1, 384, 16, 16]               0\n",
      "           Conv2d-85          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 16, 16]             768\n",
      "            ReLU6-87          [-1, 384, 16, 16]               0\n",
      "           Conv2d-88           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-90           [-1, 64, 16, 16]               0\n",
      "           Conv2d-91          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 16, 16]             768\n",
      "            ReLU6-93          [-1, 384, 16, 16]               0\n",
      "           Conv2d-94          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 16, 16]             768\n",
      "            ReLU6-96          [-1, 384, 16, 16]               0\n",
      "           Conv2d-97           [-1, 96, 16, 16]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 16, 16]             192\n",
      " InvertedResidual-99           [-1, 96, 16, 16]               0\n",
      "          Conv2d-100          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-102          [-1, 576, 16, 16]               0\n",
      "          Conv2d-103          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-105          [-1, 576, 16, 16]               0\n",
      "          Conv2d-106           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-108           [-1, 96, 16, 16]               0\n",
      "          Conv2d-109          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-111          [-1, 576, 16, 16]               0\n",
      "          Conv2d-112          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-114          [-1, 576, 16, 16]               0\n",
      "          Conv2d-115           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-117           [-1, 96, 16, 16]               0\n",
      "          Conv2d-118          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-120          [-1, 576, 16, 16]               0\n",
      "          Conv2d-121            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-123            [-1, 576, 8, 8]               0\n",
      "          Conv2d-124            [-1, 160, 8, 8]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-126            [-1, 160, 8, 8]               0\n",
      "          Conv2d-127            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-129            [-1, 960, 8, 8]               0\n",
      "          Conv2d-130            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-132            [-1, 960, 8, 8]               0\n",
      "          Conv2d-133            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-135            [-1, 160, 8, 8]               0\n",
      "          Conv2d-136            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-138            [-1, 960, 8, 8]               0\n",
      "          Conv2d-139            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-141            [-1, 960, 8, 8]               0\n",
      "          Conv2d-142            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-144            [-1, 160, 8, 8]               0\n",
      "          Conv2d-145            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-147            [-1, 960, 8, 8]               0\n",
      "          Conv2d-148            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-150            [-1, 960, 8, 8]               0\n",
      "          Conv2d-151            [-1, 320, 8, 8]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 8, 8]             640\n",
      "InvertedResidual-153            [-1, 320, 8, 8]               0\n",
      "          Conv2d-154           [-1, 1280, 8, 8]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 8, 8]           2,560\n",
      "           ReLU6-156           [-1, 1280, 8, 8]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                    [-1, 3]           3,843\n",
      "================================================================\n",
      "Total params: 2,227,715\n",
      "Trainable params: 2,227,715\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 186.93\n",
      "Params size (MB): 8.50\n",
      "Estimated Total Size (MB): 196.11\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepstation/anaconda3/envs/jetson/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:804: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/home/deepstation/anaconda3/envs/jetson/lib/python3.7/site-packages/PIL/Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.6045878016773392 | Acc:75.74074074074075 (818/1080)\n",
      "Test Loss:3.0280396789312363 | Acc:57.93357933579336 (157/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_0.pkl\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss:0.272894749089199 | Acc:90.27777777777777 (975/1080)\n",
      "Test Loss:1.5765681266784668 | Acc:87.82287822878229 (238/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_1.pkl\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss:0.14357558856992161 | Acc:94.44444444444444 (1020/1080)\n",
      "Test Loss:1.3240554630756378 | Acc:89.66789667896678 (243/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_2.pkl\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss:0.12078468139995546 | Acc:96.20370370370371 (1039/1080)\n",
      "Test Loss:1.4547280371189117 | Acc:88.19188191881919 (239/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_3.pkl\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss:0.10298864159952192 | Acc:96.57407407407408 (1043/1080)\n",
      "Test Loss:1.3929055305197835 | Acc:91.14391143911439 (247/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_4.pkl\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss:0.052105368169791555 | Acc:98.42592592592592 (1063/1080)\n",
      "Test Loss:1.225095852278173 | Acc:95.20295202952029 (258/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_5.pkl\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss:0.05572644796441583 | Acc:98.51851851851852 (1064/1080)\n",
      "Test Loss:1.3882733872160316 | Acc:94.09594095940959 (255/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_6.pkl\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss:0.022568371804321512 | Acc:98.98148148148148 (1069/1080)\n",
      "Test Loss:1.2559394659474492 | Acc:94.8339483394834 (257/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_7.pkl\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss:0.017671705021605116 | Acc:99.62962962962963 (1076/1080)\n",
      "Test Loss:1.4372992673888803 | Acc:90.03690036900369 (244/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_8.pkl\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss:0.054990622762809784 | Acc:98.42592592592592 (1063/1080)\n",
      "Test Loss:1.2343090460635722 | Acc:93.35793357933579 (253/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_9.pkl\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss:0.017603682628011003 | Acc:99.25925925925925 (1072/1080)\n",
      "Test Loss:1.4003305118530989 | Acc:91.5129151291513 (248/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_10.pkl\n",
      "\n",
      "Evaluation\n",
      "Checkpoint loaded from ./checkout/model_epoch_10.pkl\n",
      "Accuracy: 0.9077490774907749, confusion matrix: \n",
      "[[72 12  0]\n",
      " [ 1 87  3]\n",
      " [ 4  5 87]]\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    summary(model, (3, 244, 244))\n",
    "\n",
    "    train_loss_log = []\n",
    "    test_loss_log = []\n",
    "    train_acc_log = []\n",
    "    test_acc_log = []\n",
    "\n",
    "    for epoch in range(epoch_start, epochs + 1):\n",
    "        train_loss, train_acc = train(model, train_loader, epoch)\n",
    "        test_loss, test_acc = test(model, test_loader, epoch)\n",
    "        train_loss_log.append(train_loss)\n",
    "        test_loss_log.append(test_loss)\n",
    "        train_acc_log.append(train_acc)\n",
    "        test_acc_log.append(test_acc)\n",
    "        save_checkpoint(checkout_dir, epoch, model)\n",
    "    evaluation(checkout_dir, epochs, model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
