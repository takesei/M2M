{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save/load func\n",
    "def save_checkpoint(path, epoch, model):\n",
    "    save_path = os.path.join(path, f\"d_shufflenet_epoch_{epoch}.pkl\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Checkpoint saved to {save_path}\")\n",
    "\n",
    "def load_checkpoint(model_dir, epoch, model):\n",
    "    load_path = os.path.join(model_dir, f\"d_shufflenet_epoch_{epoch}.pkl\")\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(f\"Checkpoint loaded from {load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA detected\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "# random seeds\n",
    "np.random.seed(723)\n",
    "random.seed(723)\n",
    "torch.manual_seed(723)\n",
    "torch.cuda.manual_seed(723)\n",
    "\n",
    "# Networks\n",
    "batchsize = 32\n",
    "epochs = 10\n",
    "epoch_start = 1\n",
    "\n",
    "# GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"CUDA detected\")\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    \n",
    "# PATH\n",
    "checkout_dir = \"./checkout\"\n",
    "if os.path.exists(checkout_dir) is False:\n",
    "    os.mkdir(checkout_dir)\n",
    "    print(\"create ./checkout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mount model in CUDA\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "n_classes = 3\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "model = models.shufflenet_v2_x0_5(pretrained=True).to(device)\n",
    "\n",
    "n_filters = model.fc.in_features\n",
    "model.fc = nn.Linear(n_filters, n_classes)\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    print(\"mount model in CUDA\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=5e-4)\n",
    "use_scheduler= False\n",
    "if use_scheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dataset: 1351\n",
      "Number of Train Dataset: 1080\n",
      "Number of Test Dataset: 271\n",
      "epoch: 10\n",
      "batchsize: 32\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]), transforms.RandomHorizontalFlip()\n",
    "    , transforms.ToTensor()\n",
    "    , transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=\"trashes\", transform=data_transform)\n",
    "\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "print(f\"Number of Dataset: {dataset_size}\")\n",
    "print(f\"Number of Train Dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of Test Dataset: {len(test_dataset)}\")\n",
    "print(f\"epoch: {epochs}\")\n",
    "print(f\"batchsize: {batchsize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, train_loader, epoch):\n",
    "    model.train()\n",
    "    print(f\"\\nEpoch: {epoch}\")\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "    print(f\"Train Loss:{train_loss/(batch_idx+1)} | Acc:{100.*correct/total} ({correct}/{total})\")\n",
    "    return train_loss, 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(model, test_loader, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "    print(f\"Test Loss:{test_loss/batch_idx+1} | Acc:{100.*correct/total} ({correct}/{total})\")\n",
    "    return test_loss, 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluation(model_dir, epoch, model, test_loader):\n",
    "    print(\"\\nEvaluation\")\n",
    "    load_checkpoint(model_dir, epoch, model)\n",
    "    model.eval()\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outpus = model(image)\n",
    "        _, predictions = outpus.max(1)\n",
    "        y_test.append(label.data.cpu().numpy())\n",
    "        y_pred.append(predictions.data.cpu().numpy())\n",
    "    y_test = np.concatenate(y_test)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, confusion matrix: \\n{confusion_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from ./checkout/d_shufflenet_epoch_10.pkl\n"
     ]
    }
   ],
   "source": [
    "# If you want to restart learning, set model_load as True\n",
    "model_load = False\n",
    "epoch_start = 0\n",
    "\n",
    "if model_load:\n",
    "    load_checkpoint(checkout_dir, epoch_start, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 24, 122, 122]             648\n",
      "       BatchNorm2d-2         [-1, 24, 122, 122]              48\n",
      "              ReLU-3         [-1, 24, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 24, 61, 61]               0\n",
      "            Conv2d-5           [-1, 24, 31, 31]             216\n",
      "       BatchNorm2d-6           [-1, 24, 31, 31]              48\n",
      "            Conv2d-7           [-1, 24, 31, 31]             576\n",
      "       BatchNorm2d-8           [-1, 24, 31, 31]              48\n",
      "              ReLU-9           [-1, 24, 31, 31]               0\n",
      "           Conv2d-10           [-1, 24, 61, 61]             576\n",
      "      BatchNorm2d-11           [-1, 24, 61, 61]              48\n",
      "             ReLU-12           [-1, 24, 61, 61]               0\n",
      "           Conv2d-13           [-1, 24, 31, 31]             216\n",
      "      BatchNorm2d-14           [-1, 24, 31, 31]              48\n",
      "           Conv2d-15           [-1, 24, 31, 31]             576\n",
      "      BatchNorm2d-16           [-1, 24, 31, 31]              48\n",
      "             ReLU-17           [-1, 24, 31, 31]               0\n",
      " InvertedResidual-18           [-1, 48, 31, 31]               0\n",
      "           Conv2d-19           [-1, 24, 31, 31]             576\n",
      "      BatchNorm2d-20           [-1, 24, 31, 31]              48\n",
      "             ReLU-21           [-1, 24, 31, 31]               0\n",
      "           Conv2d-22           [-1, 24, 31, 31]             216\n",
      "      BatchNorm2d-23           [-1, 24, 31, 31]              48\n",
      "           Conv2d-24           [-1, 24, 31, 31]             576\n",
      "      BatchNorm2d-25           [-1, 24, 31, 31]              48\n",
      "             ReLU-26           [-1, 24, 31, 31]               0\n",
      " InvertedResidual-27           [-1, 48, 31, 31]               0\n",
      "           Conv2d-28           [-1, 24, 31, 31]             576\n",
      "      BatchNorm2d-29           [-1, 24, 31, 31]              48\n",
      "             ReLU-30           [-1, 24, 31, 31]               0\n",
      "           Conv2d-31           [-1, 24, 31, 31]             216\n",
      "      BatchNorm2d-32           [-1, 24, 31, 31]              48\n",
      "           Conv2d-33           [-1, 24, 31, 31]             576\n",
      "      BatchNorm2d-34           [-1, 24, 31, 31]              48\n",
      "             ReLU-35           [-1, 24, 31, 31]               0\n",
      " InvertedResidual-36           [-1, 48, 31, 31]               0\n",
      "           Conv2d-37           [-1, 24, 31, 31]             576\n",
      "      BatchNorm2d-38           [-1, 24, 31, 31]              48\n",
      "             ReLU-39           [-1, 24, 31, 31]               0\n",
      "           Conv2d-40           [-1, 24, 31, 31]             216\n",
      "      BatchNorm2d-41           [-1, 24, 31, 31]              48\n",
      "           Conv2d-42           [-1, 24, 31, 31]             576\n",
      "      BatchNorm2d-43           [-1, 24, 31, 31]              48\n",
      "             ReLU-44           [-1, 24, 31, 31]               0\n",
      " InvertedResidual-45           [-1, 48, 31, 31]               0\n",
      "           Conv2d-46           [-1, 48, 16, 16]             432\n",
      "      BatchNorm2d-47           [-1, 48, 16, 16]              96\n",
      "           Conv2d-48           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-49           [-1, 48, 16, 16]              96\n",
      "             ReLU-50           [-1, 48, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 31, 31]           2,304\n",
      "      BatchNorm2d-52           [-1, 48, 31, 31]              96\n",
      "             ReLU-53           [-1, 48, 31, 31]               0\n",
      "           Conv2d-54           [-1, 48, 16, 16]             432\n",
      "      BatchNorm2d-55           [-1, 48, 16, 16]              96\n",
      "           Conv2d-56           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-57           [-1, 48, 16, 16]              96\n",
      "             ReLU-58           [-1, 48, 16, 16]               0\n",
      " InvertedResidual-59           [-1, 96, 16, 16]               0\n",
      "           Conv2d-60           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-61           [-1, 48, 16, 16]              96\n",
      "             ReLU-62           [-1, 48, 16, 16]               0\n",
      "           Conv2d-63           [-1, 48, 16, 16]             432\n",
      "      BatchNorm2d-64           [-1, 48, 16, 16]              96\n",
      "           Conv2d-65           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      " InvertedResidual-68           [-1, 96, 16, 16]               0\n",
      "           Conv2d-69           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-70           [-1, 48, 16, 16]              96\n",
      "             ReLU-71           [-1, 48, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]             432\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "           Conv2d-74           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-75           [-1, 48, 16, 16]              96\n",
      "             ReLU-76           [-1, 48, 16, 16]               0\n",
      " InvertedResidual-77           [-1, 96, 16, 16]               0\n",
      "           Conv2d-78           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-79           [-1, 48, 16, 16]              96\n",
      "             ReLU-80           [-1, 48, 16, 16]               0\n",
      "           Conv2d-81           [-1, 48, 16, 16]             432\n",
      "      BatchNorm2d-82           [-1, 48, 16, 16]              96\n",
      "           Conv2d-83           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-84           [-1, 48, 16, 16]              96\n",
      "             ReLU-85           [-1, 48, 16, 16]               0\n",
      " InvertedResidual-86           [-1, 96, 16, 16]               0\n",
      "           Conv2d-87           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-88           [-1, 48, 16, 16]              96\n",
      "             ReLU-89           [-1, 48, 16, 16]               0\n",
      "           Conv2d-90           [-1, 48, 16, 16]             432\n",
      "      BatchNorm2d-91           [-1, 48, 16, 16]              96\n",
      "           Conv2d-92           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-93           [-1, 48, 16, 16]              96\n",
      "             ReLU-94           [-1, 48, 16, 16]               0\n",
      " InvertedResidual-95           [-1, 96, 16, 16]               0\n",
      "           Conv2d-96           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-97           [-1, 48, 16, 16]              96\n",
      "             ReLU-98           [-1, 48, 16, 16]               0\n",
      "           Conv2d-99           [-1, 48, 16, 16]             432\n",
      "     BatchNorm2d-100           [-1, 48, 16, 16]              96\n",
      "          Conv2d-101           [-1, 48, 16, 16]           2,304\n",
      "     BatchNorm2d-102           [-1, 48, 16, 16]              96\n",
      "            ReLU-103           [-1, 48, 16, 16]               0\n",
      "InvertedResidual-104           [-1, 96, 16, 16]               0\n",
      "          Conv2d-105           [-1, 48, 16, 16]           2,304\n",
      "     BatchNorm2d-106           [-1, 48, 16, 16]              96\n",
      "            ReLU-107           [-1, 48, 16, 16]               0\n",
      "          Conv2d-108           [-1, 48, 16, 16]             432\n",
      "     BatchNorm2d-109           [-1, 48, 16, 16]              96\n",
      "          Conv2d-110           [-1, 48, 16, 16]           2,304\n",
      "     BatchNorm2d-111           [-1, 48, 16, 16]              96\n",
      "            ReLU-112           [-1, 48, 16, 16]               0\n",
      "InvertedResidual-113           [-1, 96, 16, 16]               0\n",
      "          Conv2d-114           [-1, 48, 16, 16]           2,304\n",
      "     BatchNorm2d-115           [-1, 48, 16, 16]              96\n",
      "            ReLU-116           [-1, 48, 16, 16]               0\n",
      "          Conv2d-117           [-1, 48, 16, 16]             432\n",
      "     BatchNorm2d-118           [-1, 48, 16, 16]              96\n",
      "          Conv2d-119           [-1, 48, 16, 16]           2,304\n",
      "     BatchNorm2d-120           [-1, 48, 16, 16]              96\n",
      "            ReLU-121           [-1, 48, 16, 16]               0\n",
      "InvertedResidual-122           [-1, 96, 16, 16]               0\n",
      "          Conv2d-123             [-1, 96, 8, 8]             864\n",
      "     BatchNorm2d-124             [-1, 96, 8, 8]             192\n",
      "          Conv2d-125             [-1, 96, 8, 8]           9,216\n",
      "     BatchNorm2d-126             [-1, 96, 8, 8]             192\n",
      "            ReLU-127             [-1, 96, 8, 8]               0\n",
      "          Conv2d-128           [-1, 96, 16, 16]           9,216\n",
      "     BatchNorm2d-129           [-1, 96, 16, 16]             192\n",
      "            ReLU-130           [-1, 96, 16, 16]               0\n",
      "          Conv2d-131             [-1, 96, 8, 8]             864\n",
      "     BatchNorm2d-132             [-1, 96, 8, 8]             192\n",
      "          Conv2d-133             [-1, 96, 8, 8]           9,216\n",
      "     BatchNorm2d-134             [-1, 96, 8, 8]             192\n",
      "            ReLU-135             [-1, 96, 8, 8]               0\n",
      "InvertedResidual-136            [-1, 192, 8, 8]               0\n",
      "          Conv2d-137             [-1, 96, 8, 8]           9,216\n",
      "     BatchNorm2d-138             [-1, 96, 8, 8]             192\n",
      "            ReLU-139             [-1, 96, 8, 8]               0\n",
      "          Conv2d-140             [-1, 96, 8, 8]             864\n",
      "     BatchNorm2d-141             [-1, 96, 8, 8]             192\n",
      "          Conv2d-142             [-1, 96, 8, 8]           9,216\n",
      "     BatchNorm2d-143             [-1, 96, 8, 8]             192\n",
      "            ReLU-144             [-1, 96, 8, 8]               0\n",
      "InvertedResidual-145            [-1, 192, 8, 8]               0\n",
      "          Conv2d-146             [-1, 96, 8, 8]           9,216\n",
      "     BatchNorm2d-147             [-1, 96, 8, 8]             192\n",
      "            ReLU-148             [-1, 96, 8, 8]               0\n",
      "          Conv2d-149             [-1, 96, 8, 8]             864\n",
      "     BatchNorm2d-150             [-1, 96, 8, 8]             192\n",
      "          Conv2d-151             [-1, 96, 8, 8]           9,216\n",
      "     BatchNorm2d-152             [-1, 96, 8, 8]             192\n",
      "            ReLU-153             [-1, 96, 8, 8]               0\n",
      "InvertedResidual-154            [-1, 192, 8, 8]               0\n",
      "          Conv2d-155             [-1, 96, 8, 8]           9,216\n",
      "     BatchNorm2d-156             [-1, 96, 8, 8]             192\n",
      "            ReLU-157             [-1, 96, 8, 8]               0\n",
      "          Conv2d-158             [-1, 96, 8, 8]             864\n",
      "     BatchNorm2d-159             [-1, 96, 8, 8]             192\n",
      "          Conv2d-160             [-1, 96, 8, 8]           9,216\n",
      "     BatchNorm2d-161             [-1, 96, 8, 8]             192\n",
      "            ReLU-162             [-1, 96, 8, 8]               0\n",
      "InvertedResidual-163            [-1, 192, 8, 8]               0\n",
      "          Conv2d-164           [-1, 1024, 8, 8]         196,608\n",
      "     BatchNorm2d-165           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-166           [-1, 1024, 8, 8]               0\n",
      "          Linear-167                    [-1, 3]           3,075\n",
      "================================================================\n",
      "Total params: 344,867\n",
      "Trainable params: 344,867\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 31.07\n",
      "Params size (MB): 1.32\n",
      "Estimated Total Size (MB): 33.06\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss:0.29061077841941046 | Acc:93.05555555555556 (1005/1080)\n",
      "Test Loss:1.4439189620316029 | Acc:84.87084870848709 (230/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_10.pkl\n",
      "\n",
      "Epoch: 11\n",
      "Train Loss:0.22122608125209808 | Acc:94.9074074074074 (1025/1080)\n",
      "Test Loss:1.4394720196723938 | Acc:85.23985239852398 (231/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_11.pkl\n",
      "\n",
      "Epoch: 12\n",
      "Train Loss:0.16411042607882442 | Acc:96.11111111111111 (1038/1080)\n",
      "Test Loss:1.3408733066171408 | Acc:89.2988929889299 (242/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_12.pkl\n",
      "\n",
      "Epoch: 13\n",
      "Train Loss:0.11735980431823169 | Acc:97.22222222222223 (1050/1080)\n",
      "Test Loss:1.3065706547349691 | Acc:88.92988929889299 (241/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_13.pkl\n",
      "\n",
      "Epoch: 14\n",
      "Train Loss:0.08904379693900838 | Acc:98.61111111111111 (1065/1080)\n",
      "Test Loss:1.3075243011116982 | Acc:90.4059040590406 (245/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_14.pkl\n",
      "\n",
      "Epoch: 15\n",
      "Train Loss:0.07179326607900507 | Acc:98.88888888888889 (1068/1080)\n",
      "Test Loss:1.332699722610414 | Acc:90.4059040590406 (245/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_15.pkl\n",
      "\n",
      "Epoch: 16\n",
      "Train Loss:0.07389429003438529 | Acc:98.51851851851852 (1064/1080)\n",
      "Test Loss:1.2932524746283889 | Acc:87.82287822878229 (238/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_16.pkl\n",
      "\n",
      "Epoch: 17\n",
      "Train Loss:0.05977374715182711 | Acc:98.61111111111111 (1065/1080)\n",
      "Test Loss:1.3219615630805492 | Acc:89.2988929889299 (242/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_17.pkl\n",
      "\n",
      "Epoch: 18\n",
      "Train Loss:0.05032658259219983 | Acc:99.25925925925925 (1072/1080)\n",
      "Test Loss:1.2547204927541316 | Acc:92.619926199262 (251/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_18.pkl\n",
      "\n",
      "Epoch: 19\n",
      "Train Loss:0.03524032333756194 | Acc:99.72222222222223 (1077/1080)\n",
      "Test Loss:1.309375286102295 | Acc:91.88191881918819 (249/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_19.pkl\n",
      "\n",
      "Epoch: 20\n",
      "Train Loss:0.027581057949539495 | Acc:99.9074074074074 (1079/1080)\n",
      "Test Loss:1.2557486919686198 | Acc:93.7269372693727 (254/271)\n",
      "Checkpoint saved to ./checkout/d_shufflenet_epoch_20.pkl\n",
      "\n",
      "Evaluation\n",
      "Checkpoint loaded from ./checkout/d_shufflenet_epoch_10.pkl\n",
      "Accuracy: 0.8634686346863468, confusion matrix: \n",
      "[[77  4  3]\n",
      " [ 9 95  5]\n",
      " [12  4 62]]\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    summary(model, (3, 244, 244))\n",
    "\n",
    "    train_loss_log = []\n",
    "    test_loss_log = []\n",
    "    train_acc_log = []\n",
    "    test_acc_log = []\n",
    "\n",
    "    for epoch in range(epoch_start, epochs + 1):\n",
    "        train_loss, train_acc = train(model, train_loader, epoch)\n",
    "        test_loss, test_acc = test(model, test_loader, epoch)\n",
    "        train_loss_log.append(train_loss)\n",
    "        test_loss_log.append(test_loss)\n",
    "        train_acc_log.append(train_acc)\n",
    "        test_acc_log.append(test_acc)\n",
    "        save_checkpoint(checkout_dir, epoch, model)\n",
    "    evaluation(checkout_dir, epochs, model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
