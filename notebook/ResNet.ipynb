{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save/load func\n",
    "def save_checkpoint(path, epoch, model):\n",
    "    save_path = os.path.join(path, f\"resnet_epoch_{epoch}.pkl\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Checkpoint saved to {save_path}\")\n",
    "\n",
    "def load_checkpoint(model_dir, epoch, model):\n",
    "    load_path = os.path.join(model_dir, f\"resnet_epoch_{epoch}.pkl\")\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(f\"Checkpoint loaded from {load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA detected\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "# random seeds\n",
    "np.random.seed(723)\n",
    "random.seed(723)\n",
    "torch.manual_seed(723)\n",
    "torch.cuda.manual_seed(723)\n",
    "\n",
    "# Networks\n",
    "batchsize = 32\n",
    "epochs = 10\n",
    "epoch_start = 1\n",
    "\n",
    "# GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"CUDA detected\")\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    \n",
    "# PATH\n",
    "checkout_dir = \"./checkout\"\n",
    "if os.path.exists(checkout_dir) is False:\n",
    "    os.mkdir(checkout_dir)\n",
    "    print(\"create ./checkout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mount model in CUDA\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "n_classes = 3\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "n_filters = model.fc.in_features\n",
    "model.fc = nn.Linear(n_filters, n_classes)\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    print(\"mount model in CUDA\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=5e-4)\n",
    "use_scheduler= False\n",
    "if use_scheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dataset: 1351\n",
      "Number of Train Dataset: 1080\n",
      "Number of Test Dataset: 271\n",
      "epoch: 10\n",
      "batchsize: 32\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]), transforms.RandomHorizontalFlip()\n",
    "    , transforms.ToTensor()\n",
    "    , transforms.Normalize((0.4919, 0.4822, 0.4655), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=\"trashes\", transform=data_transform)\n",
    "\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "print(f\"Number of Dataset: {dataset_size}\")\n",
    "print(f\"Number of Train Dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of Test Dataset: {len(test_dataset)}\")\n",
    "print(f\"epoch: {epochs}\")\n",
    "print(f\"batchsize: {batchsize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, train_loader, epoch):\n",
    "    model.train()\n",
    "    print(f\"\\nEpoch: {epoch}\")\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "    print(f\"Train Loss:{train_loss/(batch_idx+1)} | Acc:{100.*correct/total} ({correct}/{total})\")\n",
    "    return train_loss, 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(model, test_loader, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += label.size(0)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "    print(f\"Test Loss:{test_loss/batch_idx+1} | Acc:{100.*correct/total} ({correct}/{total})\")\n",
    "    return test_loss, 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluation(model_dir, epoch, model, test_loader):\n",
    "    print(\"\\nEvaluation\")\n",
    "    load_checkpoint(model_dir, epoch, model)\n",
    "    model.eval()\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for batch_idx, (image, label) in enumerate(test_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        outpus = model(image)\n",
    "        _, predictions = outpus.max(1)\n",
    "        y_test.append(label.data.cpu().numpy())\n",
    "        y_pred.append(predictions.data.cpu().numpy())\n",
    "    y_test = np.concatenate(y_test)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, confusion matrix: \\n{confusion_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to restart learning, set model_load as True\n",
    "model_load = False\n",
    "epoch_start = 0\n",
    "\n",
    "if model_load:\n",
    "    load_checkpoint(checkout_dir, epoch_start, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
      "              ReLU-3         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
      "            Conv2d-5           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
      "              ReLU-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-11           [-1, 64, 61, 61]               0\n",
      "           Conv2d-12           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 61, 61]             128\n",
      "             ReLU-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 31, 31]             256\n",
      "             ReLU-21          [-1, 128, 31, 31]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "           Conv2d-24          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 31, 31]             256\n",
      "             ReLU-26          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-27          [-1, 128, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 31, 31]             256\n",
      "             ReLU-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-34          [-1, 128, 31, 31]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 3]           1,539\n",
      "================================================================\n",
      "Total params: 11,178,051\n",
      "Trainable params: 11,178,051\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 76.08\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 119.40\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepstation/anaconda3/envs/jetson/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:804: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/home/deepstation/anaconda3/envs/jetson/lib/python3.7/site-packages/PIL/Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:0.5823712600942921 | Acc:76.01851851851852 (821/1080)\n",
      "Test Loss:1.6605772748589516 | Acc:79.33579335793358 (215/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_0.pkl\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss:0.26384234527016387 | Acc:91.57407407407408 (989/1080)\n",
      "Test Loss:1.4450489170849323 | Acc:87.45387453874538 (237/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_1.pkl\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss:0.18332016950144486 | Acc:93.61111111111111 (1011/1080)\n",
      "Test Loss:1.6122268997132778 | Acc:87.82287822878229 (238/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_2.pkl\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss:0.05538378371035352 | Acc:97.96296296296296 (1058/1080)\n",
      "Test Loss:1.1878579542972147 | Acc:96.30996309963099 (261/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_3.pkl\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss:0.04748044696444755 | Acc:98.61111111111111 (1065/1080)\n",
      "Test Loss:1.235338516999036 | Acc:94.09594095940959 (255/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_4.pkl\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss:0.01870080584879307 | Acc:99.53703703703704 (1075/1080)\n",
      "Test Loss:1.131808447651565 | Acc:95.5719557195572 (259/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_5.pkl\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss:0.03725506887627382 | Acc:98.79629629629629 (1067/1080)\n",
      "Test Loss:1.1671527046710253 | Acc:96.30996309963099 (261/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_6.pkl\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss:0.016773347345673862 | Acc:99.35185185185185 (1073/1080)\n",
      "Test Loss:1.1894320379942656 | Acc:94.8339483394834 (257/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_7.pkl\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss:0.015029039088403806 | Acc:99.35185185185185 (1073/1080)\n",
      "Test Loss:1.192505069077015 | Acc:95.5719557195572 (259/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_8.pkl\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss:0.014737089767175563 | Acc:99.72222222222223 (1077/1080)\n",
      "Test Loss:1.2042145235463977 | Acc:95.5719557195572 (259/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_9.pkl\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss:0.020554503206821048 | Acc:99.07407407407408 (1070/1080)\n",
      "Test Loss:1.1648096698336303 | Acc:95.9409594095941 (260/271)\n",
      "Checkpoint saved to ./checkout/model_epoch_10.pkl\n",
      "\n",
      "Evaluation\n",
      "Checkpoint loaded from ./checkout/model_epoch_10.pkl\n",
      "Accuracy: 0.966789667896679, confusion matrix: \n",
      "[[84  5  0]\n",
      " [ 1 94  0]\n",
      " [ 2  1 84]]\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    summary(model, (3, 244, 244))\n",
    "\n",
    "    train_loss_log = []\n",
    "    test_loss_log = []\n",
    "    train_acc_log = []\n",
    "    test_acc_log = []\n",
    "\n",
    "    for epoch in range(epoch_start, epochs + 1):\n",
    "        train_loss, train_acc = train(model, train_loader, epoch)\n",
    "        test_loss, test_acc = test(model, test_loader, epoch)\n",
    "        train_loss_log.append(train_loss)\n",
    "        test_loss_log.append(test_loss)\n",
    "        train_acc_log.append(train_acc)\n",
    "        test_acc_log.append(test_acc)\n",
    "        save_checkpoint(checkout_dir, epoch, model)\n",
    "    evaluation(checkout_dir, epochs, model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
